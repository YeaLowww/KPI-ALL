# -*- coding: utf-8 -*-
"""AI_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qpffp7U8v5ebk3CQvhF1F9yYPxXTOEuY
"""

# TensorFlow and tf.keras
import tensorflow as tf

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)

cifar10 = tf.keras.datasets.cifar10

(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',
               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']
print(train_images.shape)
print(train_labels)
print(test_images.shape)
# Данные должны быть предварительно обработаны перед обучением сети.
# Если вы посмотрите на первое изображение в тренировочном наборе, вы увидите, что значения пикселей попадают в диапазон от 0 до 255:
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()
#Масштабируйте эти значения в диапазоне от 0 до 1, прежде чем передавать их в модель нейронной сети. Для этого разделите значения на 255.
train_images = train_images / 255.0

test_images = test_images / 255.0
#Чтобы убедиться, что данные имеют правильный формат и что вы готовы построить и обучить сеть,
# давайте отобразим первые 25 изображений из обучающего набора и отобразим имя класса под каждым изображением.
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()

###Настройка слоев
# После выравнивания пикселей сеть состоит из последовательности двух слоев tf.keras.layers.Dense .
# Это плотно связанные или полностью связанные нейронные слои.
# лише один шар Dense перед фінальним вихідним шаром, що повертає результат для кожного з 10 класів без активації. Ось як виглядає нова архітектура моделі:

# Flatten: перетворює вхідні дані зображення у вектор.

# Dense (128 нейронів): густий шар з 128 нейронами та функцією активації relu.

# Dense (10 нейронів): фінальний густий шар з 10 нейронами для класифікації на 10 класів без функції активації
# (з огляду на from_logits=True у вашій функції втрати).
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])

#Скомпилируйте модель
# Функция потерь — измеряет, насколько точна модель во время обучения. Вы хотите минимизировать эту функцию, чтобы "направить" модель в правильном направлении.
# Оптимизатор — именно так модель обновляется на основе данных, которые она видит, и ее функции потерь.
# Метрики — используются для мониторинга этапов обучения и тестирования. В следующем примере используется точность , доля правильно классифицированных изображений.
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
#Обучите модель
# Для обучения модели нейронной сети необходимо выполнить следующие шаги:

# Подайте обучающие данные к модели. В этом примере обучающие данные находятся в train_images и train_labels .
# Модель учится связывать изображения и метки.
# Вы просите модель сделать прогноз относительно тестового набора — в этом примере массива test_images .
# Убедитесь, что прогнозы соответствуют меткам из массива test_labels .
# Перетворення зображень у формат (None, 32, 32)
# Перетворення зображень у формат (None, 32, 32, 3)
train_images_resized = train_images.reshape(train_images.shape[0], 32, 32, 3)
test_images_resized = test_images.reshape(test_images.shape[0], 32, 32, 3)

# Масштабування значень пікселів до діапазону [0, 1]
train_images_rescaled = train_images_resized / 255.0
test_images_rescaled = test_images_resized / 255.0

# Навчання моделі
model.fit(train_images_rescaled, train_labels, epochs=50)

# Получается, что точность на тестовом наборе данных немного меньше, чем точность на обучающем наборе данных.
#Этот разрыв между точностью обучения и точностью теста представляет собой переоснащение .
#Переоснащение происходит, когда модель машинного обучения работает хуже с новыми, ранее невиданными входными данными, чем с обучающими данными.
#Переобученная модель «запоминает» шум и детали в обучающем наборе данных до такой степени, что это негативно влияет на производительность модели на новых данных.
test_loss, test_accuracy = model.evaluate(test_images_rescaled, test_labels, verbose=2)
print(f"Точність на тестовому наборі даних: {test_accuracy}")
# Додаємо шар Softmax
probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])

# Зроблення передбачень для тестового набору даних
predictions = probability_model.predict(test_images_rescaled)

# Виведення передбачених класів для перших 15 зображень
print(predictions[0])
print(np.argmax(predictions[0]))

# Кількість зображень, які ви хочете вивести
num_images = 15

# Перебираємо перші num_images зображень з тестового набору
for i in range(num_images):
    # Вибираємо зображення та його мітку
    img = test_images[i]
    actual_label = class_names[test_labels[i][0]]

    # Зроблення прогнозу для вибраного зображення
    predictions_single = probability_model.predict(img.reshape(1, 32, 32, 3))
    predicted_class = np.argmax(predictions_single)
    predicted_label = class_names[predicted_class]

    # Вивід зображення та його прогнозу
    plt.figure(figsize=(3, 3))
    plt.imshow(img)
    plt.colorbar()
    plt.grid(False)
    plt.title(f"Predicted: {predicted_label} ({np.max(predictions_single)*100:.2f}%)")
    plt.xlabel("Actual: " + actual_label)
    plt.show()