# -*- coding: utf-8 -*-
"""text lab4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rk9XkQ5sMb5cpRBedRBaIMCqGotardyH
"""

# В якості текстової моделі використати модель «Сумка слів».
# Виконати класифікацію за допомогою алгоритмів логістична регресія та градієнтний бустинг, порівняти їх точність.
# Спробувати покращити моделі за допомогою  GridSearchCV.

import pandas as pd

content_df = pd.read_csv('bbc-news-data.csv', sep='\t')
content_df

"""Попередня обробка документів"""

print(f'Duplicates count: {content_df.duplicated().sum()}')
content_df.isna().sum()

import re
from nltk.tokenize import WordPunctTokenizer
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')
stop_words = stopwords.words('english')
tokenizer = WordPunctTokenizer()


def preprocess_document(doc):
    doc = re.sub(r'[^a-zA-Z\s]', '', doc, re.I | re.A)
    doc = doc.lower()
    doc = doc.strip()
    tokens = tokenizer.tokenize(doc)
    filtered_tokens = [token for token in tokens if token not in stop_words]
    doc = ' '.join(filtered_tokens)
    return doc
content_df['CleanedContent'] = content_df['content'].apply(preprocess_document)
content_df.head()

"""Розділення на навчальні та тестові набори

Вилучення ознак з використанням моделі BoW

---
"""

from sklearn.model_selection import train_test_split
train_corpus, test_corpus, train_label_names, test_label_names = train_test_split(content_df['CleanedContent'],
                                                                                  content_df['category'], test_size=0.2,
                                                                                  stratify=content_df['category'],
                                                                                  random_state=1234)
from sklearn.feature_extraction.text import CountVectorizer

bow_vectorizer = CountVectorizer()
bow_train_features = bow_vectorizer.fit_transform(train_corpus)
bow_test_features = bow_vectorizer.transform(test_corpus)

"""Класифікація за допомогою логістичної регресії"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

unique_classes = list(set(test_label_names))
logistic_regression = LogisticRegression()
logistic_regression.fit(bow_train_features, train_label_names)
predicted_labels = logistic_regression.predict(bow_test_features)
print(classification_report(test_label_names, predicted_labels, labels=unique_classes))

"""Класифікація за допомогою градієнтого бустингу"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report

gbc = GradientBoostingClassifier()
gbc.fit(bow_train_features, train_label_names)
predicted_labels = gbc.predict(bow_test_features)
print(classification_report(test_label_names, predicted_labels, labels=unique_classes))

"""Покращення моделей за допомогою GridSearchCV"""

from sklearn.model_selection import GridSearchCV


def tune_model(model, param_grid):
    model_cv = GridSearchCV(model, param_grid=param_grid, n_jobs=-1)
    model_cv.fit(bow_train_features, train_label_names)
    print(f"Best parameters: {model_cv.best_params_}")
    print(f"Train accuracy: {model_cv.best_score_}")
    print(f"Test accuracy: {model_cv.score(bow_test_features, test_label_names)}")
    return model_cv.best_estimator_

logistic_regression = LogisticRegression(max_iter=1000)
param_grid = {'C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10]}
logistic_regression_cv = tune_model(logistic_regression, param_grid)

import numpy as np

param_grid = {'n_estimators': np.arange(100, 140, 10)}
gbc = GradientBoostingClassifier()
gbc_cv = tune_model(gbc, param_grid)