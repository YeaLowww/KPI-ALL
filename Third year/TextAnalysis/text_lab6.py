# -*- coding: utf-8 -*-
"""text_lab_6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12NfkjDqIPCHWIuKfSbssopU5pi-AVBwj

1.Файл Reddit.csv. -1 – негативний коментар, 0 – нейтральний, 1 – позитивний. Використати опорні вектори
2. Файл lab6-4.txt. а) Знайти та вивести іменники жіночого роду, які присутні у тексті. б) Вивести леми слів першого речення. в) Знайти та вивести організації, які присутні у тексті.

Створити програму, яка:
1. а) Зчитує заданий набір даних, виконує попередню обробку, розбиває
дані на навчальні на тестові. Виконує аналіз настроїв за допомогою
алгоритмів класифікації (наприклад, логістичної регресії, опорних
векторів і т.д.). Виводить матрицю невідповідностей та точність моделі.
б) Використовує один з готових лексиконів, наприклад Textblob, для
аналізу оцінки настроїв. Також розраховує матрицю невідповідностей, та
точність моделі.
в) Обирає три випадкові записи та виводить результати оцінки їх настрою
за пунктами а) і б).
"""

import numpy as np
import pandas as pd
import nltk
import re
df = pd.read_csv('Reddit.csv', sep=',')
df

from sklearn.preprocessing import LabelEncoder
category_encoder = LabelEncoder()
df['category'] = category_encoder.fit_transform(df.category)
df

from sklearn.feature_extraction.text import TfidfVectorizer
# Fill missing values in 'clean_comment' column with an empty string
df['clean_comment'] = df['clean_comment'].fillna('')

tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)
df_x = tv.fit_transform(df.clean_comment)
df_y = df['category'].values
df_x

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

def conf_mat(model, x_test, y_test):
    y_predicted = model.predict(x_test)
    cm = confusion_matrix(y_test, y_predicted)
    plt.figure(figsize=(8, 5))
    sns.heatmap(cm, annot=True, fmt=".1f")
    plt.xlabel('Predicted')

from sklearn.metrics import roc_curve, roc_auc_score
def roc(model, x_test, y_test):
    y_pred_proba = model.predict_proba(x_test)[::,1]
    fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)
    auc = roc_auc_score(y_test, y_pred_proba)
    plt.plot(fpr,tpr,label="Area = "+str(auc)+')')
    plt.plot([0, 1], [0, 1],'r--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver operating characteristic')
    plt.legend(loc=4)
    plt.show()

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(
    df_x, df_y, test_size=0.3, random_state=0)
x_train.shape, x_test.shape

from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
models = {
    'lin_svc': LinearSVC(penalty='l2', C=1, random_state=0),

}

def get_results(models, x_train, y_train, x_test, y_test) -> dict:
    results = []
    for name, model in models.items():
        model.fit(x_train, y_train)
        results.append((name, {
                'model': model,
                'train': model.score(x_train, y_train),
                'test': model.score(x_test, y_test),
            })
        )
    return dict(results)

results = get_results(models, x_train, y_train, x_test, y_test)
results

conf_mat(results['lin_svc']['model'], x_test, y_test)

from textblob import TextBlob
# Вибрати три випадкові записи
random_samples = df.sample(3)

# Вивести вміст цих записів
for idx, row in random_samples.iterrows():
    print(f"Запис {idx}:")
    print(row['clean_comment'])
    print("\n")

# Оцінити настрій за пунктами а) і б)
for idx, row in random_samples.iterrows():
    print(f"Оцінка настрою для запису {idx}:")
    # Оцінка за пунктом а)
    prediction_a = results['lin_svc']['model'].predict(tv.transform([row['clean_comment']]))
    print(f"Аналіз класифікації: {category_encoder.inverse_transform(prediction_a)}")

    # Оцінка за пунктом б)
    tb_result = TextBlob(row['clean_comment']).sentiment.polarity
    if -0.2 <= tb_result < 0:
        prediction_b = -1
    elif 0 <= tb_result < 0.5:
        prediction_b = 0
    else:
        prediction_b = 1
    print(f"Аналіз TextBlob: {prediction_b}")
    print("\n")





import spacy
import stanza

# Завантаження універсальної моделі spaCy для розпізнавання іменованих сутностей
spacy_nlp = spacy.load('xx_ent_wiki_sm')

# Завантаження української моделі Stanza для визначення частин мови та лемматизації
stanza.download('uk')
stanza_nlp = stanza.Pipeline('uk')

# Читання файлу
file_path = 'lab6-4.txt'
with open(file_path, 'r', encoding='utf-8') as file:
    text = file.read()

# Аналіз тексту за допомогою spaCy для розпізнавання іменованих сутностей
spacy_doc = spacy_nlp(text)

# Аналіз тексту за допомогою Stanza для частин мови та лемматизації
stanza_doc = stanza_nlp(text)

# Завдання а): Знайти іменники жіночого роду за допомогою Stanza
female_nouns = [word.text for sentence in stanza_doc.sentences for word in sentence.words if word.upos == 'NOUN' and word.feats and 'Gender=Fem' in word.feats]
print("Іменники жіночого роду:", female_nouns)

# Завдання б): Вивести леми слів першого речення за допомогою Stanza
first_sentence = stanza_doc.sentences[0]
first_sentence_lemmas = [word.lemma for word in first_sentence.words]
print("Леми слів першого речення:", first_sentence_lemmas)

# Завдання в): Знайти та вивести організації за допомогою spaCy
organizations = [ent.text for ent in spacy_doc.ents if ent.label_ == 'ORG']
print("Організації:", organizations)