# -*- coding: utf-8 -*-
"""text_lab3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bjQR1ExxyaYqvUgrKs2RkEf4zL-efYwO

Зчитати файл doc2. Вважати кожен рядок окремим документом корпусу.
Виконати попередню обробку корпусу.
"""

with open('doc2.txt') as file:
    corpus = [line.rstrip() for line in file]
print(corpus)

from nltk.tokenize import WordPunctTokenizer
from nltk.corpus import stopwords
import re
import nltk
nltk.download('stopwords')

stop_words = stopwords.words('english')
tokenizer = WordPunctTokenizer()


def preprocess_document(doc):
    doc = re.sub(r'[^a-zA-Z\s]', '', doc, re.I | re.A)
    doc = doc.lower()
    doc = doc.strip()
    tokens = tokenizer.tokenize(doc)
    filtered_tokens = [token for token in tokens if token not in stop_words]
    doc = ' '.join(filtered_tokens)
    return doc
import numpy as np
import pandas as pd

preprocess_corpus = np.vectorize(preprocess_document)
preprocessed_corpus = preprocess_corpus(corpus)
corpus_df = pd.DataFrame(preprocessed_corpus, columns=['Document'])
corpus_df

"""
1)Представити корпус як модель «Сумка n-грам», взяти біграми."""

from sklearn.feature_extraction.text import CountVectorizer

count_vectorizer = CountVectorizer(ngram_range=(2, 2))
bv_matrix = count_vectorizer.fit_transform(preprocessed_corpus)
print(bv_matrix)

import pandas as pd

vocab = count_vectorizer.get_feature_names_out()
bag_of_words = pd.DataFrame(bv_matrix.toarray(), columns=vocab)
bag_of_words

"""Вивести вектор для orange juice.

"""

bag_of_words['orange juice']

"""2)Представити корпус як модель TF-IDF.

"""

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer()
tv_matrix = tfidf_vectorizer.fit_transform(preprocessed_corpus)

"""Спробувати кластеризувати документи за допомогою ієрархічної агломераційної кластеризації."""

from sklearn.metrics.pairwise import cosine_similarity

similarity_matrix = cosine_similarity(tv_matrix)
similarity_matrix

from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt

links = linkage(similarity_matrix, 'ward')
plt.figure(figsize=(8, 6))
plt.xlabel('Documents')
plt.ylabel('Distance')
dendrogram(links)
plt.show()

from scipy.cluster.hierarchy import fcluster

max_dist = 1.4
cluster_labels = fcluster(links, max_dist, criterion='distance')
cluster_labels = pd.DataFrame(cluster_labels, columns=[' ClusterLabel'])
pd.concat([corpus_df, cluster_labels], axis=1)

"""3)Представити корпус як модель FastText.
Знайти подібні слова до слів Algeria, combine.
"""

from gensim.models.fasttext import FastText

tokenized_corpus = [doc.split() for doc in preprocessed_corpus]
ft_model = FastText(tokenized_corpus, vector_size=300, min_count=1, sg=1)
similar_words = {search_term: [item[0] for item in ft_model.wv.most_similar([search_term], topn=5)] for search_term in ['Algeria', 'combine']}
similar_words